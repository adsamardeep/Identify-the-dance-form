{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dancer.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adsamardeep/Identify-the-dance-form/blob/master/hackathons/hackerearth_dancer1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SELcKmW4JMEw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "99a23b79-7ab4-417a-d588-c72a23334f3f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rjhy63kQIRVn",
        "colab_type": "code",
        "outputId": "b253acfd-d8cb-4de5-f1b1-817712f4fd65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import PIL\n",
        "import cv2 ,pickle\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wb_BWgwDI9d5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data = pd.read_csv(\"/content/drive/My Drive/HackerEarth/IdentifyDanceForms/test.csv\")\n",
        "train_data = pd.read_csv(\"/content/drive/My Drive/HackerEarth/IdentifyDanceForms/train.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQQ42QZaJLDA",
        "colab_type": "code",
        "outputId": "9e243c64-932b-42cd-ca4f-18e8fb4f2a88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "test_data.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Image</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>508.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>246.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>473.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>485.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>128.jpg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Image\n",
              "0  508.jpg\n",
              "1  246.jpg\n",
              "2  473.jpg\n",
              "3  485.jpg\n",
              "4  128.jpg"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHqVpiYPJMiv",
        "colab_type": "code",
        "outputId": "e24ad64c-6cc5-4944-fe4a-8ace2efffe09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "train_data.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Image</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>96.jpg</td>\n",
              "      <td>manipuri</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>163.jpg</td>\n",
              "      <td>bharatanatyam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>450.jpg</td>\n",
              "      <td>odissi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>219.jpg</td>\n",
              "      <td>kathakali</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>455.jpg</td>\n",
              "      <td>odissi</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Image         target\n",
              "0   96.jpg       manipuri\n",
              "1  163.jpg  bharatanatyam\n",
              "2  450.jpg         odissi\n",
              "3  219.jpg      kathakali\n",
              "4  455.jpg         odissi"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYaOoIu5JOR9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = []\n",
        "for i in train_data[\"Image\"]:\n",
        "    path = \"/content/drive/My Drive/HackerEarth/IdentifyDanceForms/train/\"+i\n",
        "    img_data = cv2.imread(path)\n",
        "    img_data = cv2.resize(img_data, (224, 224), \n",
        "                           interpolation=cv2.INTER_NEAREST)\n",
        "    train.append(np.array(img_data))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVK2Pz02L685",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test = []\n",
        "for i in test_data[\"Image\"]:\n",
        "  path = \"/content/drive/My Drive/HackerEarth/IdentifyDanceForms/test/\"+i\n",
        "  img_data = cv2.imread(path)\n",
        "  img_data = cv2.resize(img_data, (224, 224), \n",
        "                           interpolation=cv2.INTER_NEAREST)\n",
        "  test.append(np.array(img_data))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQFoNf7GoE_b",
        "colab_type": "code",
        "outputId": "081ab730-5e1d-48a8-e6ec-c877f68a2574",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train[0].shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(224, 224, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKiEQJwcMWHQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "pickle.dump(train,open(\"/content/drive/My Drive/HackerEarth/IdentifyDanceForms/train.npy\",\"wb\"))\n",
        "pickle.dump(test, open(\"/content/drive/My Drive/HackerEarth/IdentifyDanceForms/test.npy\",\"wb\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEBR0pgPM6js",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_img = pickle.load(open(\"/content/drive/My Drive/HackerEarth/IdentifyDanceForms/test.npy\",\"rb\"))\n",
        "train_img = pickle.load(open(\"/content/drive/My Drive/HackerEarth/IdentifyDanceForms/train.npy\",\"rb\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TlLLJQWJM8je",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_img = np.array(train_img)\n",
        "test_img = np.array(test_img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_USJJlkRcmG",
        "colab_type": "code",
        "outputId": "901753cd-1d99-4804-fde4-733dea218faf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "train_data.head() "
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Image</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>96.jpg</td>\n",
              "      <td>manipuri</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>163.jpg</td>\n",
              "      <td>bharatanatyam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>450.jpg</td>\n",
              "      <td>odissi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>219.jpg</td>\n",
              "      <td>kathakali</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>455.jpg</td>\n",
              "      <td>odissi</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Image         target\n",
              "0   96.jpg       manipuri\n",
              "1  163.jpg  bharatanatyam\n",
              "2  450.jpg         odissi\n",
              "3  219.jpg      kathakali\n",
              "4  455.jpg         odissi"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gLICAtjRdRU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder = LabelEncoder()\n",
        "encoder.fit(train_data[\"target\"])\n",
        "encoded_Y = encoder.transform(train_data[\"target\"])\n",
        "dummy_y = np_utils.to_categorical(encoded_Y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqqk7b6r5-x5",
        "colab_type": "code",
        "outputId": "07771e0f-0743-4036-ab8a-b402133973c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dummy_y.shape"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(364, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRwD_Se86LVU",
        "colab_type": "code",
        "outputId": "a75e6904-3d02-4302-b6e0-74dcc8307033",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_img.shape"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(364, 224, 224, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9f1wNk4W6tbn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Flatten\n",
        "from keras.wrappers.scikit_learn import KerasClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cswm7Gr8JRZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating a Sequential model\n",
        "model= Sequential()\n",
        "model.add(Conv2D(kernel_size=(3,3), filters=3, activation='relu', input_shape=train_img[0].shape))\n",
        "model.add(Conv2D(filters=3,kernel_size = (3,3),activation='relu'))\n",
        "model.add(MaxPool2D(3,3))\n",
        "model.add(Conv2D(filters=3,kernel_size = (3,3),activation='relu'))\n",
        "model.add(MaxPool2D(3,3))\n",
        "model.add(Conv2D(filters=3,kernel_size = (3,3),activation='relu'))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(20,activation='relu'))\n",
        "model.add(Dense(15,activation='relu'))\n",
        "model.add(Dense(8,activation = 'softmax'))\n",
        "    \n",
        "model.compile(\n",
        "              loss='categorical_crossentropy', \n",
        "              metrics=['acc'],\n",
        "              optimizer='adam'\n",
        "             )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8oHwXbH_Cr1",
        "colab_type": "code",
        "outputId": "611286cc-28bc-4977-dde2-e717c53bda02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_5 (Conv2D)            (None, 222, 222, 3)       84        \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 220, 220, 3)       84        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 73, 73, 3)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 71, 71, 3)         84        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 23, 23, 3)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 21, 21, 3)         84        \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 1323)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 20)                26480     \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 15)                315       \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 8)                 128       \n",
            "=================================================================\n",
            "Total params: 27,259\n",
            "Trainable params: 27,259\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Z-dW7RfAwlO",
        "colab_type": "code",
        "outputId": "49dfc9b8-a937-497a-da8c-3ccf9d60b85f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = model.fit(train_img, dummy_y, epochs=50, batch_size=50)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "364/364 [==============================] - 7s 18ms/step - loss: 6.8655 - acc: 0.1676\n",
            "Epoch 2/50\n",
            "364/364 [==============================] - 0s 548us/step - loss: 2.6331 - acc: 0.2033\n",
            "Epoch 3/50\n",
            "364/364 [==============================] - 0s 556us/step - loss: 2.0813 - acc: 0.2143\n",
            "Epoch 4/50\n",
            "364/364 [==============================] - 0s 552us/step - loss: 1.9488 - acc: 0.2555\n",
            "Epoch 5/50\n",
            "364/364 [==============================] - 0s 538us/step - loss: 1.8249 - acc: 0.3214\n",
            "Epoch 6/50\n",
            "364/364 [==============================] - 0s 548us/step - loss: 1.7226 - acc: 0.3599\n",
            "Epoch 7/50\n",
            "364/364 [==============================] - 0s 545us/step - loss: 1.6143 - acc: 0.4066\n",
            "Epoch 8/50\n",
            "364/364 [==============================] - 0s 573us/step - loss: 1.4950 - acc: 0.4588\n",
            "Epoch 9/50\n",
            "364/364 [==============================] - 0s 541us/step - loss: 1.3512 - acc: 0.5220\n",
            "Epoch 10/50\n",
            "364/364 [==============================] - 0s 541us/step - loss: 1.2164 - acc: 0.5852\n",
            "Epoch 11/50\n",
            "364/364 [==============================] - 0s 542us/step - loss: 1.1040 - acc: 0.5962\n",
            "Epoch 12/50\n",
            "364/364 [==============================] - 0s 526us/step - loss: 0.9835 - acc: 0.6346\n",
            "Epoch 13/50\n",
            "364/364 [==============================] - 0s 545us/step - loss: 0.8752 - acc: 0.6703\n",
            "Epoch 14/50\n",
            "364/364 [==============================] - 0s 546us/step - loss: 0.7708 - acc: 0.7088\n",
            "Epoch 15/50\n",
            "364/364 [==============================] - 0s 536us/step - loss: 0.6874 - acc: 0.7445\n",
            "Epoch 16/50\n",
            "364/364 [==============================] - 0s 540us/step - loss: 0.6143 - acc: 0.7885\n",
            "Epoch 17/50\n",
            "364/364 [==============================] - 0s 524us/step - loss: 0.5229 - acc: 0.8187\n",
            "Epoch 18/50\n",
            "364/364 [==============================] - 0s 548us/step - loss: 0.4540 - acc: 0.8462\n",
            "Epoch 19/50\n",
            "364/364 [==============================] - 0s 532us/step - loss: 0.3894 - acc: 0.8544\n",
            "Epoch 20/50\n",
            "364/364 [==============================] - 0s 524us/step - loss: 0.3598 - acc: 0.8819\n",
            "Epoch 21/50\n",
            "364/364 [==============================] - 0s 530us/step - loss: 0.2910 - acc: 0.9011\n",
            "Epoch 22/50\n",
            "364/364 [==============================] - 0s 550us/step - loss: 0.2336 - acc: 0.9258\n",
            "Epoch 23/50\n",
            "364/364 [==============================] - 0s 557us/step - loss: 0.1897 - acc: 0.9478\n",
            "Epoch 24/50\n",
            "364/364 [==============================] - 0s 534us/step - loss: 0.1593 - acc: 0.9615\n",
            "Epoch 25/50\n",
            "364/364 [==============================] - 0s 544us/step - loss: 0.1202 - acc: 0.9643\n",
            "Epoch 26/50\n",
            "364/364 [==============================] - 0s 535us/step - loss: 0.1118 - acc: 0.9725\n",
            "Epoch 27/50\n",
            "364/364 [==============================] - 0s 535us/step - loss: 0.0952 - acc: 0.9753\n",
            "Epoch 28/50\n",
            "364/364 [==============================] - 0s 550us/step - loss: 0.0742 - acc: 0.9753\n",
            "Epoch 29/50\n",
            "364/364 [==============================] - 0s 528us/step - loss: 0.0669 - acc: 0.9835\n",
            "Epoch 30/50\n",
            "364/364 [==============================] - 0s 526us/step - loss: 0.0542 - acc: 0.9890\n",
            "Epoch 31/50\n",
            "364/364 [==============================] - 0s 534us/step - loss: 0.0430 - acc: 0.9918\n",
            "Epoch 32/50\n",
            "364/364 [==============================] - 0s 534us/step - loss: 0.0364 - acc: 0.9918\n",
            "Epoch 33/50\n",
            "364/364 [==============================] - 0s 531us/step - loss: 0.0299 - acc: 0.9945\n",
            "Epoch 34/50\n",
            "364/364 [==============================] - 0s 552us/step - loss: 0.0280 - acc: 0.9918\n",
            "Epoch 35/50\n",
            "364/364 [==============================] - 0s 537us/step - loss: 0.0243 - acc: 0.9945\n",
            "Epoch 36/50\n",
            "364/364 [==============================] - 0s 538us/step - loss: 0.0526 - acc: 0.9945\n",
            "Epoch 37/50\n",
            "364/364 [==============================] - 0s 541us/step - loss: 0.0302 - acc: 0.9945\n",
            "Epoch 38/50\n",
            "364/364 [==============================] - 0s 555us/step - loss: 0.0439 - acc: 0.9945\n",
            "Epoch 39/50\n",
            "364/364 [==============================] - 0s 567us/step - loss: 0.0323 - acc: 0.9918\n",
            "Epoch 40/50\n",
            "364/364 [==============================] - 0s 533us/step - loss: 0.0429 - acc: 0.9918\n",
            "Epoch 41/50\n",
            "364/364 [==============================] - 0s 556us/step - loss: 0.0333 - acc: 0.9918\n",
            "Epoch 42/50\n",
            "364/364 [==============================] - 0s 534us/step - loss: 0.0205 - acc: 0.9945\n",
            "Epoch 43/50\n",
            "364/364 [==============================] - 0s 546us/step - loss: 0.0148 - acc: 0.9973\n",
            "Epoch 44/50\n",
            "364/364 [==============================] - 0s 575us/step - loss: 0.0140 - acc: 0.9945\n",
            "Epoch 45/50\n",
            "364/364 [==============================] - 0s 531us/step - loss: 0.0124 - acc: 0.9973\n",
            "Epoch 46/50\n",
            "364/364 [==============================] - 0s 532us/step - loss: 0.0112 - acc: 0.9973\n",
            "Epoch 47/50\n",
            "364/364 [==============================] - 0s 525us/step - loss: 0.0104 - acc: 0.9973\n",
            "Epoch 48/50\n",
            "364/364 [==============================] - 0s 534us/step - loss: 0.0099 - acc: 0.9973\n",
            "Epoch 49/50\n",
            "364/364 [==============================] - 0s 571us/step - loss: 0.0096 - acc: 0.9973\n",
            "Epoch 50/50\n",
            "364/364 [==============================] - 0s 543us/step - loss: 0.0092 - acc: 0.9973\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVvxDlISQqPN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPQoCEAFBsGv",
        "colab_type": "code",
        "outputId": "20807150-4122-492a-8fcf-5cdd6067c985",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YsGK_nsoDB7b",
        "colab_type": "code",
        "outputId": "29d38404-640f-4721-9fb8-7191841c959a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uydd-7ClDDpN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = model.predict_classes(test_img)\n",
        "pred = encoder.inverse_transform(pred)\n",
        "result = pd.DataFrame(pred, test_data[\"Image\"], columns=[\"target\"])\n",
        "result.to_csv(\"sample1.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zul1pH7LoWkW",
        "colab_type": "text"
      },
      "source": [
        "Resnet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBgtWvVnoVt_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsv7pUcxoVqU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "27bb89c3-7945-408e-ed27-e89bec49ffb1"
      },
      "source": [
        "base_model = ResNet50(\n",
        "    weights='imagenet',\n",
        "    include_top=False, \n",
        "    input_shape=(224, 224, 3), \n",
        "    pooling='avg'\n",
        ")"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11xR-sCxoVof",
        "colab_type": "code",
        "outputId": "897710e3-9320-46cf-8190-647a3f313d4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "base_model.trainable = False\n",
        "\n",
        "model = Sequential([\n",
        "  base_model,\n",
        "  Dropout(0.2),\n",
        "  Dense(8, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "resnet50 (Model)             (None, 2048)              23587712  \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 8)                 16392     \n",
            "=================================================================\n",
            "Total params: 23,604,104\n",
            "Trainable params: 16,392\n",
            "Non-trainable params: 23,587,712\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlwnFLYdoVlR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "checkpoint = ModelCheckpoint('best_model.h5',\n",
        "                             monitor='val_loss', \n",
        "                             verbose=1, save_best_only= True, \n",
        "                             mode='auto')    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPjPzs8aoViP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size =5\n",
        "epochs = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QS9NWO4ioVeF",
        "colab_type": "code",
        "outputId": "ca1df840-57d9-4ad6-b859-1c0586829383",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "datagen = ImageDataGenerator(\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True)\n",
        "\n",
        "training_generator = datagen.flow(train_img, dummy_y,\n",
        "                                  batch_size=batch_size)\n",
        "\n",
        "history = model.fit_generator(\n",
        "         training_generator,\n",
        "         steps_per_epoch= training_generator.n//training_generator.batch_size,\n",
        "         callbacks=[checkpoint],\n",
        "         epochs= epochs)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-43-b1a96aceacbf>:13: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "Epoch 1/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 2.1628 - accuracy: 0.2841WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 55ms/step - loss: 2.1628 - accuracy: 0.2841\n",
            "Epoch 2/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 1.0773 - accuracy: 0.6379WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 55ms/step - loss: 1.0773 - accuracy: 0.6379\n",
            "Epoch 3/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.8990 - accuracy: 0.6769WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 54ms/step - loss: 0.8990 - accuracy: 0.6769\n",
            "Epoch 4/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.7075 - accuracy: 0.7604WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 54ms/step - loss: 0.7075 - accuracy: 0.7604\n",
            "Epoch 5/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.5370 - accuracy: 0.8357WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 54ms/step - loss: 0.5370 - accuracy: 0.8357\n",
            "Epoch 6/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.5183 - accuracy: 0.8189WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 52ms/step - loss: 0.5183 - accuracy: 0.8189\n",
            "Epoch 7/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.4181 - accuracy: 0.8635WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 54ms/step - loss: 0.4181 - accuracy: 0.8635\n",
            "Epoch 8/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.4669 - accuracy: 0.8496WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 54ms/step - loss: 0.4669 - accuracy: 0.8496\n",
            "Epoch 9/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.2834 - accuracy: 0.9220WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 55ms/step - loss: 0.2834 - accuracy: 0.9220\n",
            "Epoch 10/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.2972 - accuracy: 0.9081WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 54ms/step - loss: 0.2972 - accuracy: 0.9081\n",
            "Epoch 11/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.2649 - accuracy: 0.9164WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 54ms/step - loss: 0.2649 - accuracy: 0.9164\n",
            "Epoch 12/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.2596 - accuracy: 0.9248WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 54ms/step - loss: 0.2596 - accuracy: 0.9248\n",
            "Epoch 13/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.1916 - accuracy: 0.9526WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 54ms/step - loss: 0.1916 - accuracy: 0.9526\n",
            "Epoch 14/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.2518 - accuracy: 0.9220WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 53ms/step - loss: 0.2518 - accuracy: 0.9220\n",
            "Epoch 15/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.1576 - accuracy: 0.9582WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 53ms/step - loss: 0.1576 - accuracy: 0.9582\n",
            "Epoch 16/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.2040 - accuracy: 0.9443WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 53ms/step - loss: 0.2040 - accuracy: 0.9443\n",
            "Epoch 17/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.1581 - accuracy: 0.9610WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 53ms/step - loss: 0.1581 - accuracy: 0.9610\n",
            "Epoch 18/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.2226 - accuracy: 0.9331WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 54ms/step - loss: 0.2226 - accuracy: 0.9331\n",
            "Epoch 19/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.1219 - accuracy: 0.9721WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 54ms/step - loss: 0.1219 - accuracy: 0.9721\n",
            "Epoch 20/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.1418 - accuracy: 0.9610WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 54ms/step - loss: 0.1418 - accuracy: 0.9610\n",
            "Epoch 21/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.1387 - accuracy: 0.9694WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 54ms/step - loss: 0.1387 - accuracy: 0.9694\n",
            "Epoch 22/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.1435 - accuracy: 0.9610WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 54ms/step - loss: 0.1435 - accuracy: 0.9610\n",
            "Epoch 23/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.1650 - accuracy: 0.9471WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 54ms/step - loss: 0.1650 - accuracy: 0.9471\n",
            "Epoch 24/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0879 - accuracy: 0.9889WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 53ms/step - loss: 0.0879 - accuracy: 0.9889\n",
            "Epoch 25/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.1124 - accuracy: 0.9721WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 53ms/step - loss: 0.1124 - accuracy: 0.9721\n",
            "Epoch 26/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.1262 - accuracy: 0.9638WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 54ms/step - loss: 0.1262 - accuracy: 0.9638\n",
            "Epoch 27/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.1064 - accuracy: 0.9666WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 52ms/step - loss: 0.1064 - accuracy: 0.9666\n",
            "Epoch 28/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.1151 - accuracy: 0.9721WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 52ms/step - loss: 0.1151 - accuracy: 0.9721\n",
            "Epoch 29/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.1137 - accuracy: 0.9638WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 53ms/step - loss: 0.1137 - accuracy: 0.9638\n",
            "Epoch 30/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.1077 - accuracy: 0.9721WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 54ms/step - loss: 0.1077 - accuracy: 0.9721\n",
            "Epoch 31/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0903 - accuracy: 0.9721WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 54ms/step - loss: 0.0903 - accuracy: 0.9721\n",
            "Epoch 32/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0902 - accuracy: 0.9721WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 53ms/step - loss: 0.0902 - accuracy: 0.9721\n",
            "Epoch 33/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0621 - accuracy: 0.9889WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 53ms/step - loss: 0.0621 - accuracy: 0.9889\n",
            "Epoch 34/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0825 - accuracy: 0.9721WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 54ms/step - loss: 0.0825 - accuracy: 0.9721\n",
            "Epoch 35/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0953 - accuracy: 0.9694WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 54ms/step - loss: 0.0953 - accuracy: 0.9694\n",
            "Epoch 36/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0891 - accuracy: 0.9749WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 53ms/step - loss: 0.0891 - accuracy: 0.9749\n",
            "Epoch 37/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0621 - accuracy: 0.9861WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 53ms/step - loss: 0.0621 - accuracy: 0.9861\n",
            "Epoch 38/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.1160 - accuracy: 0.9582WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 53ms/step - loss: 0.1160 - accuracy: 0.9582\n",
            "Epoch 39/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0930 - accuracy: 0.9666WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 53ms/step - loss: 0.0930 - accuracy: 0.9666\n",
            "Epoch 40/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0792 - accuracy: 0.9833WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 54ms/step - loss: 0.0792 - accuracy: 0.9833\n",
            "Epoch 41/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0908 - accuracy: 0.9694WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 55ms/step - loss: 0.0908 - accuracy: 0.9694\n",
            "Epoch 42/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0747 - accuracy: 0.9833WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 55ms/step - loss: 0.0747 - accuracy: 0.9833\n",
            "Epoch 43/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0637 - accuracy: 0.9805WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 54ms/step - loss: 0.0637 - accuracy: 0.9805\n",
            "Epoch 44/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0699 - accuracy: 0.9777WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 53ms/step - loss: 0.0699 - accuracy: 0.9777\n",
            "Epoch 45/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0592 - accuracy: 0.9833WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 54ms/step - loss: 0.0592 - accuracy: 0.9833\n",
            "Epoch 46/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0695 - accuracy: 0.9861WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 53ms/step - loss: 0.0695 - accuracy: 0.9861\n",
            "Epoch 47/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0551 - accuracy: 0.9861WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 52ms/step - loss: 0.0551 - accuracy: 0.9861\n",
            "Epoch 48/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0477 - accuracy: 0.9861WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 53ms/step - loss: 0.0477 - accuracy: 0.9861\n",
            "Epoch 49/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0460 - accuracy: 0.9889WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 54ms/step - loss: 0.0460 - accuracy: 0.9889\n",
            "Epoch 50/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0574 - accuracy: 0.9833WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 54ms/step - loss: 0.0574 - accuracy: 0.9833\n",
            "Epoch 51/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0413 - accuracy: 0.9916WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 54ms/step - loss: 0.0413 - accuracy: 0.9916\n",
            "Epoch 52/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0501 - accuracy: 0.9833WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 54ms/step - loss: 0.0501 - accuracy: 0.9833\n",
            "Epoch 53/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0524 - accuracy: 0.9972WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 53ms/step - loss: 0.0524 - accuracy: 0.9972\n",
            "Epoch 54/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0323 - accuracy: 0.9944WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 54ms/step - loss: 0.0323 - accuracy: 0.9944\n",
            "Epoch 55/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0252 - accuracy: 1.0000WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 53ms/step - loss: 0.0252 - accuracy: 1.0000\n",
            "Epoch 56/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0401 - accuracy: 0.9944WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 54ms/step - loss: 0.0401 - accuracy: 0.9944\n",
            "Epoch 57/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0687 - accuracy: 0.9777WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 54ms/step - loss: 0.0687 - accuracy: 0.9777\n",
            "Epoch 58/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0411 - accuracy: 0.9889WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 53ms/step - loss: 0.0411 - accuracy: 0.9889\n",
            "Epoch 59/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0653 - accuracy: 0.9833WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 53ms/step - loss: 0.0653 - accuracy: 0.9833\n",
            "Epoch 60/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0757 - accuracy: 0.9721WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 54ms/step - loss: 0.0757 - accuracy: 0.9721\n",
            "Epoch 61/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0568 - accuracy: 0.9889WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 54ms/step - loss: 0.0568 - accuracy: 0.9889\n",
            "Epoch 62/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0586 - accuracy: 0.9805WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 54ms/step - loss: 0.0586 - accuracy: 0.9805\n",
            "Epoch 63/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0557 - accuracy: 0.9777WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 54ms/step - loss: 0.0557 - accuracy: 0.9777\n",
            "Epoch 64/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0529 - accuracy: 0.9861WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 54ms/step - loss: 0.0529 - accuracy: 0.9861\n",
            "Epoch 65/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0417 - accuracy: 0.9916WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 54ms/step - loss: 0.0417 - accuracy: 0.9916\n",
            "Epoch 66/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0932 - accuracy: 0.9666WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 54ms/step - loss: 0.0932 - accuracy: 0.9666\n",
            "Epoch 67/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0542 - accuracy: 0.9777WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 54ms/step - loss: 0.0542 - accuracy: 0.9777\n",
            "Epoch 68/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0540 - accuracy: 0.9777WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 54ms/step - loss: 0.0540 - accuracy: 0.9777\n",
            "Epoch 69/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0395 - accuracy: 0.9889WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 54ms/step - loss: 0.0395 - accuracy: 0.9889\n",
            "Epoch 70/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0295 - accuracy: 0.9916WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 54ms/step - loss: 0.0295 - accuracy: 0.9916\n",
            "Epoch 71/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0637 - accuracy: 0.9805WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 53ms/step - loss: 0.0637 - accuracy: 0.9805\n",
            "Epoch 72/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0425 - accuracy: 0.9889WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 52ms/step - loss: 0.0425 - accuracy: 0.9889\n",
            "Epoch 73/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0234 - accuracy: 0.9944WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 53ms/step - loss: 0.0234 - accuracy: 0.9944\n",
            "Epoch 74/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0493 - accuracy: 0.9833WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 55ms/step - loss: 0.0493 - accuracy: 0.9833\n",
            "Epoch 75/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0559 - accuracy: 0.9861WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 55ms/step - loss: 0.0559 - accuracy: 0.9861\n",
            "Epoch 76/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0376 - accuracy: 0.9861WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 55ms/step - loss: 0.0376 - accuracy: 0.9861\n",
            "Epoch 77/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0433 - accuracy: 0.9889WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 53ms/step - loss: 0.0433 - accuracy: 0.9889\n",
            "Epoch 78/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0253 - accuracy: 0.9916WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 54ms/step - loss: 0.0253 - accuracy: 0.9916\n",
            "Epoch 79/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0339 - accuracy: 0.9916WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 54ms/step - loss: 0.0339 - accuracy: 0.9916\n",
            "Epoch 80/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0420 - accuracy: 0.9889WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 54ms/step - loss: 0.0420 - accuracy: 0.9889\n",
            "Epoch 81/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0816 - accuracy: 0.9694WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 54ms/step - loss: 0.0816 - accuracy: 0.9694\n",
            "Epoch 82/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0323 - accuracy: 0.9944WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 55ms/step - loss: 0.0323 - accuracy: 0.9944\n",
            "Epoch 83/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0273 - accuracy: 0.9944WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 54ms/step - loss: 0.0273 - accuracy: 0.9944\n",
            "Epoch 84/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0157 - accuracy: 1.0000WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 54ms/step - loss: 0.0157 - accuracy: 1.0000\n",
            "Epoch 85/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0359 - accuracy: 0.9916WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 54ms/step - loss: 0.0359 - accuracy: 0.9916\n",
            "Epoch 86/100\n",
            "71/72 [============================>.] - ETA: 0s - loss: 0.0569 - accuracy: 0.9859WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 53ms/step - loss: 0.0563 - accuracy: 0.9861\n",
            "Epoch 87/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0533 - accuracy: 0.9833WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 54ms/step - loss: 0.0533 - accuracy: 0.9833\n",
            "Epoch 88/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0805 - accuracy: 0.9694WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 53ms/step - loss: 0.0805 - accuracy: 0.9694\n",
            "Epoch 89/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0872 - accuracy: 0.9721WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 52ms/step - loss: 0.0872 - accuracy: 0.9721\n",
            "Epoch 90/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0234 - accuracy: 0.9944WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 54ms/step - loss: 0.0234 - accuracy: 0.9944\n",
            "Epoch 91/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0160 - accuracy: 0.9972WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 54ms/step - loss: 0.0160 - accuracy: 0.9972\n",
            "Epoch 92/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0235 - accuracy: 0.9972WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 54ms/step - loss: 0.0235 - accuracy: 0.9972\n",
            "Epoch 93/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0650 - accuracy: 0.9833WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 54ms/step - loss: 0.0650 - accuracy: 0.9833\n",
            "Epoch 94/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0670 - accuracy: 0.9777WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 53ms/step - loss: 0.0670 - accuracy: 0.9777\n",
            "Epoch 95/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0410 - accuracy: 0.9833WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 54ms/step - loss: 0.0410 - accuracy: 0.9833\n",
            "Epoch 96/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0454 - accuracy: 0.9833WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 53ms/step - loss: 0.0454 - accuracy: 0.9833\n",
            "Epoch 97/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0155 - accuracy: 0.9944WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 55ms/step - loss: 0.0155 - accuracy: 0.9944\n",
            "Epoch 98/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0618 - accuracy: 0.9805WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 55ms/step - loss: 0.0618 - accuracy: 0.9805\n",
            "Epoch 99/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0769 - accuracy: 0.9805WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 54ms/step - loss: 0.0769 - accuracy: 0.9805\n",
            "Epoch 100/100\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0333 - accuracy: 0.9944WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "72/72 [==============================] - 4s 53ms/step - loss: 0.0333 - accuracy: 0.9944\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6O82lZQoVYR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = model.predict(test_img)\n",
        "pred = np.argmax(pred, axis=1)\n",
        "test_data = pd.read_csv(\"/content/drive/My Drive/HackerEarth/IdentifyDanceForms/test.csv\")\n",
        "\n",
        "pred = encoder.inverse_transform(pred)\n",
        "result = pd.DataFrame(pred, test_data[\"Image\"], columns=[\"target\"])\n",
        "result.to_csv(\"sample2.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTPjtUpToVVd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqsXfzSkoVR0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}